# Î Î¡ÎŸÎ’Î›Î•Î¨Î— Î¤Î™ÎœÎ©Î ÎœÎ•Î¤ÎŸÎ§Î©Î NFLX ÎœÎ• Î“Î¡Î‘ÎœÎœÎ™ÎšÎ— Î Î‘Î›Î™ÎÎ”Î¡ÎŸÎœÎ—Î£Î—

# NFLX Stock Price Prediction with Linear Regression

**Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ­Ï‚ ÎœÎ­Î¸Î¿Î´Î¿Î¹ ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ®Ï‚ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚ - Î•ÏÎ³Î±ÏƒÎ¯Î± 1**  
**Statistical Methods of Machine Learning - Task 1**

---

## Î•Î Î™Î£ÎšÎŸÎ Î—Î£Î— Î•Î¡Î“ÎŸÎ¥ / PROJECT OVERVIEW

Î‘Ï…Ï„ÏŒ Ï„Î¿ Î­ÏÎ³Î¿ Ï…Î»Î¿Ï€Î¿Î¹ÎµÎ¯ Î¼Î¹Î± Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î· Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯Î± Î¼Î·Ï‡Î±Î½Î¹ÎºÎ®Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Ï„Î¹Î¼ÏÎ½ Î¼ÎµÏ„Î¿Ï‡ÏÎ½ Netflix (NFLX) Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î³ÏÎ±Î¼Î¼Î¹ÎºÎ® Ï€Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· ÎºÎ±Î¹ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ Ï€ÏÎ¿Î·Î³Î¼Î­Î½ÎµÏ‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚.

This project implements a comprehensive machine learning pipeline to predict Netflix (NFLX) stock prices using linear regression and various advanced techniques.

### Î•ÏÎ³Î±ÏƒÎ¯ÎµÏ‚ / Tasks

- **Î•ÏÎ³Î±ÏƒÎ¯Î± Î‘ / Task A**: Baseline Î“ÏÎ±Î¼Î¼Î¹ÎºÎ® Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· / Baseline Linear Regression
- **Î•ÏÎ³Î±ÏƒÎ¯Î± Î’ / Task B**: Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ® Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· Î¼Îµ L1/L2 ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· / Polynomial Regression with L1/L2 Regularization
- **Î•ÏÎ³Î±ÏƒÎ¯Î± Î“ / Task C**: ÎœÎµÎ¯Ï‰ÏƒÎ· Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½ (PCA, CFS, Wrapper) / Dimensionality Reduction (PCA, CFS, Wrapper Methods)
- **Î•ÏÎ³Î±ÏƒÎ¯Î± Î” / Task D**: Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎœÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÏÎ½ Î¤Î¹Î¼ÏÎ½ (Î”ÎµÎºÎ­Î¼Î²ÏÎ¹Î¿Ï‚ 2025, Î™Î±Î½Î¿Ï…Î¬ÏÎ¹Î¿Ï‚ 2026) / Future Price Predictions (December 2025, January 2026)

**Î£ÏÎ¼Î²Î¿Î»Î¿ ÎœÎµÏ„Î¿Ï‡Î®Ï‚ / Stock Symbol**: NFLX (Netflix, Inc.)  
**Î¤Î¿Î¼Î­Î±Ï‚ / Sector**: Communication Services  
**Î Î·Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Data Source**: Alpha Vantage API

---

## Î£Î¥ÎÎŸÎ›Î™ÎšÎ‘ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘ / COMPREHENSIVE RESULTS

### ğŸ“Š ÎœÎ¿Î½Ï„Î­Î»Î± Ï€Î¿Ï… Î‘Î½Î±Î»ÏÎ¸Î·ÎºÎ±Î½ / Models Analyzed

**Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î± / Total Models: 96**

- âœ… **16 Baseline** Linear Regression Î¼Î¿Î½Ï„Î­Î»Î± (4 smoothing Ã— 4 lags)
- âœ… **32 Polynomial** Regression Î¼Î¿Î½Ï„Î­Î»Î± (Ridge + Lasso Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏÏÎ¸Î¼Î¹ÏƒÎ· / for each config)
- âœ… **48 Dimensionality Reduction** Î¼Î¿Î½Ï„Î­Î»Î± (PCA + CFS + Sequential Forward Selection)

### ğŸ† ÎšÎ‘Î›Î¥Î¤Î•Î¡Î‘ ÎœÎŸÎÎ¤Î•Î›Î‘ / BEST MODELS

#### 1. ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Baseline / Best Baseline

- **ÎœÎ¿Î½Ï„Î­Î»Î¿ / Model**: Linear Regression
- **Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± / Preprocessing**: Gaussian Smoothing (Ïƒ=3)
- **Î Î±ÏÎ¬Î¸Ï…ÏÎ¿ Î¥ÏƒÏ„Î­ÏÎ·ÏƒÎ·Ï‚ / Lag Window**: 12 Î¼Î®Î½ÎµÏ‚ / months
- **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ / Features**: 24 (12 close price lags + 12 volume lags)
- **Training RMSE**: $0.02
- **Training RÂ²**: 1.0000
- **Validation RMSE**: $0.03
- **Validation RÂ²**: 1.0000

#### 2. ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Polynomial / Best Polynomial

- **ÎœÎ¿Î½Ï„Î­Î»Î¿ / Model**: Ridge Regression (Degree 2)
- **Î¡ÏÎ¸Î¼Î¹ÏƒÎ· / Configuration**: sigma3, 9 lags
- **Alpha**: 0.001
- **Validation RMSE**: $4.19
- **Validation RÂ²**: 0.9978

#### 3. ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Dimensionality Reduction / Best Dim-Reduction

- **ÎœÎ­Î¸Î¿Î´Î¿Ï‚ / Method**: Sequential Forward Selection
- **Î¡ÏÎ¸Î¼Î¹ÏƒÎ· / Configuration**: sigma3, 12 lags
- **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ / Features**: 12 (Î¼ÎµÎ¹Ï‰Î¼Î­Î½Î± Î±Ï€ÏŒ 24 / reduced from 24)
- **Validation RMSE**: $0.03
- **Validation RÂ²**: 1.0000

### ğŸ”® Î Î¡ÎŸÎ’Î›Î•Î¨Î•Î™Î£ ÎœÎ•Î›Î›ÎŸÎÎ¤Î™ÎšÎ©Î Î¤Î™ÎœÎ©Î / FUTURE PREDICTIONS

**Î”ÎµÎºÎ­Î¼Î²ÏÎ¹Î¿Ï‚ 2025 / December 2025**: $1,175.48  
**Î™Î±Î½Î¿Ï…Î¬ÏÎ¹Î¿Ï‚ 2026 / January 2026**: $1,175.95

_Î’Î±ÏƒÎ¹ÏƒÎ¼Î­Î½ÎµÏ‚ ÏƒÏ„Î¿ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ baseline Î¼Î¿Î½Ï„Î­Î»Î¿ (sigma3, 12 lags)_  
_Based on best baseline model (sigma3, 12 lags)_

---

## Î”ÎŸÎœÎ— Î•Î¡Î“ÎŸÎ¥ / PROJECT STRUCTURE

```
stock-price-linear-regression/
â”‚
â”œâ”€â”€ step1_data_acquisition.py          # Î£Ï…Î»Î»Î¿Î³Î® & Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Data fetching & preprocessing
â”œâ”€â”€ step2_feature_engineering.py       # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ Î¼Îµ Ï…ÏƒÏ„Î­ÏÎ·ÏƒÎ· / Lagged feature creation
â”œâ”€â”€ step3_baseline_linear_regression.py # Î•ÏÎ³Î±ÏƒÎ¯Î± Î‘ / Task A implementation
â”œâ”€â”€ step4_polynomial_regression_regularization.py # Î•ÏÎ³Î±ÏƒÎ¯Î± Î’ / Task B
â”œâ”€â”€ step5_dimensionality_reduction.py  # Î•ÏÎ³Î±ÏƒÎ¯Î± Î“ / Task C implementation
â”œâ”€â”€ step6_future_predictions_improved.py # Î•ÏÎ³Î±ÏƒÎ¯Î± Î” & ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ· / Task D & comprehensive analysis
â”‚
â”œâ”€â”€ data/                              # Î‘ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Î± & ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¼Î­Î½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± / Raw & processed data
â”‚   â”œâ”€â”€ nflx_monthly_raw.csv           # 283 Î¼Î®Î½ÎµÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / months of data
â”‚   â”œâ”€â”€ nflx_monthly_smoothed_sigma1.csv
â”‚   â”œâ”€â”€ nflx_monthly_smoothed_sigma2.csv
â”‚   â”œâ”€â”€ nflx_monthly_smoothed_sigma3.csv
â”‚   â””â”€â”€ smoothing_comparison.png
â”‚
â”œâ”€â”€ features/                          # Î Î¯Î½Î±ÎºÎµÏ‚ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ & scalers / Feature matrices & scalers
â”‚   â”œâ”€â”€ features_*.npz (16 ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ / configurations)
â”‚   â”œâ”€â”€ scaler_*.pkl
â”‚   â”œâ”€â”€ metadata_*.csv
â”‚   â””â”€â”€ train_val_split_*.png
â”‚
â”œâ”€â”€ models/                            # Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± Î¼Î¿Î½Ï„Î­Î»Î± / Trained models
â”‚   â”œâ”€â”€ best_baseline_linear_regression.pkl
â”‚   â”œâ”€â”€ all_polynomial_models.pkl      # 32 polynomial models
â”‚   â””â”€â”€ all_dimensionality_reduction_models.pkl # 48 dim-reduction models
â”‚
â”œâ”€â”€ results/                           # Î‘Ï€ÎµÎ¹ÎºÎ¿Î½Î¯ÏƒÎµÎ¹Ï‚ & Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ / Visualizations & reports
â”‚   â”œâ”€â”€ baseline_linear_regression_results.csv (16 models)
â”‚   â”œâ”€â”€ polynomial_regression_all_models_results.csv (32 models)
â”‚   â”œâ”€â”€ dimensionality_reduction_all_models_results.csv (48 models)
â”‚   â”œâ”€â”€ baseline_predictions_dec_jan_2025_2026.csv
â”‚   â”œâ”€â”€ COMPREHENSIVE_96_MODELS_REPORT_EL_EN.txt
â”‚   â”œâ”€â”€ baseline_performance_by_config.png
â”‚   â”œâ”€â”€ comprehensive_predictions_comparison.png
â”‚   â””â”€â”€ best_model_forecast_with_history.png
â”‚
â”œâ”€â”€ Provided Code/                     # ÎšÏÎ´Î¹ÎºÎ±Ï‚ Ï€Î±ÏÎ±Î´ÎµÎ¹Î³Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¸Î·Î³Î·Ï„Î® / Teacher's example code
â”‚   â”œâ”€â”€ data_acquisition.ipynb
â”‚   â”œâ”€â”€ regression_demo.ipynb
â”‚   â”œâ”€â”€ feature_selection.ipynb
â”‚   â”œâ”€â”€ pca_demo.ipynb
â”‚   â”œâ”€â”€ training_L1_L2.ipynb
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env                               # Î”Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ· API key / API key configuration
â”œâ”€â”€ statistical_methods_of_ml.md       # Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ / Assignment description
â”œâ”€â”€ ML_TERMINOLOGY_GLOSSARY_EL_EN.md   # Î“Î»Ï‰ÏƒÏƒÎ¬ÏÎ¹Î¿ ÏŒÏÏ‰Î½ / Terminology glossary
â””â”€â”€ README.md                          # Î‘Ï…Ï„ÏŒ Ï„Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ / This file
```

---

## Î•Î“ÎšÎ‘Î¤Î‘Î£Î¤Î‘Î£Î— & Î¡Î¥Î˜ÎœÎ™Î£Î— / INSTALLATION & SETUP

### Î ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î± / Prerequisites

```bash
Python 3.8 Î® Î½ÎµÏŒÏ„ÎµÏÎ¿ / or higher
```

### Î‘Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ / Required Libraries

```bash
pip install numpy pandas scikit-learn scipy matplotlib requests python-dateutil
```

### Î”Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ· API Key / API Key Configuration

1. Î•Î³Î³ÏÎ±Ï†ÎµÎ¯Ï„Îµ Î³Î¹Î± Î´Ï‰ÏÎµÎ¬Î½ Alpha Vantage API key ÏƒÏ„Î¿ / Sign up for a free Alpha Vantage API key at:  
   https://www.alphavantage.co/

2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Î±ÏÏ‡ÎµÎ¯Î¿ `.env` ÏƒÏ„Î· ÏÎ¯Î¶Î± Ï„Î¿Ï… project / Create a `.env` file in the project root:

```
api_key=YOUR_API_KEY_HERE
```

---

## ÎŸÎ”Î—Î“Î™Î•Î£ Î§Î¡Î—Î£Î—Î£ / USAGE INSTRUCTIONS

### Î Î»Î®ÏÎ·Ï‚ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Pipeline / Complete Pipeline Execution

Î•ÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ ÏŒÎ»Î± Ï„Î± scripts Î¼Îµ Ï„Î· ÏƒÎµÎ¹ÏÎ¬:  
Run all scripts in sequence:

```bash
# Î’Î®Î¼Î± 1: Î£Ï…Î»Î»Î¿Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Step 1: Data Acquisition
python step1_data_acquisition.py

# Î’Î®Î¼Î± 2: Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ / Step 2: Feature Engineering
python step2_feature_engineering.py

# Î’Î®Î¼Î± 3: Baseline Î“ÏÎ±Î¼Î¼Î¹ÎºÎ® Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· / Step 3: Baseline Linear Regression (Î•ÏÎ³Î±ÏƒÎ¯Î± Î‘ / Task A)
python step3_baseline_linear_regression.py

# Î’Î®Î¼Î± 4: Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ® Î Î±Î»Î¹Î½Î´ÏÏŒÎ¼Î·ÏƒÎ· / Step 4: Polynomial Regression (Î•ÏÎ³Î±ÏƒÎ¯Î± Î’ / Task B)
python step4_polynomial_regression_regularization.py

# Î’Î®Î¼Î± 5: ÎœÎµÎ¯Ï‰ÏƒÎ· Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½ / Step 5: Dimensionality Reduction (Î•ÏÎ³Î±ÏƒÎ¯Î± Î“ / Task C)
python step5_dimensionality_reduction.py

# Î’Î®Î¼Î± 6: Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎœÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÏÎ½ Î¤Î¹Î¼ÏÎ½ / Step 6: Future Predictions (Î•ÏÎ³Î±ÏƒÎ¯Î± Î” / Task D)
python step6_future_predictions_improved.py
```

### ÎœÎµÎ¼Î¿Î½Ï‰Î¼Î­Î½Î· Î•ÎºÏ„Î­Î»ÎµÏƒÎ· Î’Î·Î¼Î¬Ï„Ï‰Î½ / Individual Step Execution

ÎšÎ¬Î¸Îµ script Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÎºÏ„ÎµÎ»ÎµÏƒÏ„ÎµÎ¯ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î± Î±Ï†Î¿Ï Î­Ï‡Î¿Ï…Î½ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¸ÎµÎ¯ Ï„Î± Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î± Î²Î®Î¼Î±Ï„Î±.  
Each script can be run independently after previous steps are completed.

---

## Î›Î•Î Î¤ÎŸÎœÎ•Î¡Î•Î™Î•Î£ ÎœÎ•Î˜ÎŸÎ”ÎŸÎ›ÎŸÎ“Î™Î‘Î£ / METHODOLOGY DETAILS

### 1. Î£Ï…Î»Î»Î¿Î³Î® & Î ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Data Acquisition & Preprocessing

- **Î Î·Î³Î® / Source**: Alpha Vantage API (NFLX daily data)
- **Î§ÏÎ¿Î½Î¹ÎºÎ® Î ÎµÏÎ¯Î¿Î´Î¿Ï‚ / Time Period**: ÎœÎ¬Î¹Î¿Ï‚ 2002 - ÎÎ¿Î­Î¼Î²ÏÎ¹Î¿Ï‚ 2025 / May 2002 - November 2025
- **Î£Ï…Î½Î¿Î»Î¹ÎºÎ¿Î¯ ÎœÎ®Î½ÎµÏ‚ / Total Months**: 283
- **Smoothing**: Gaussian filter (Ïƒ = 0, 1, 2, 3)
- **ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ / Metrics**: Close price & Volume

### 2. Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÏÎ½ / Feature Engineering

- **Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î¼Îµ Î¥ÏƒÏ„Î­ÏÎ·ÏƒÎ· / Lagged Features**: close_t-1, close_t-2, ..., close_t-N & volume_t-1, ..., volume_t-N
- **Î Î±ÏÎ¬Î¸Ï…ÏÎ± Î¥ÏƒÏ„Î­ÏÎ·ÏƒÎ·Ï‚ Ï€Î¿Ï… Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Î·ÎºÎ±Î½ / Lag Windows Tested**: 3, 6, 9, 12 Î¼Î®Î½ÎµÏ‚ / months
- **Î”Î¹Î±Î¯ÏÎµÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Data Split**:
  - Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· / Training: < 2025 (260-269 Î´ÎµÎ¯Î³Î¼Î±Ï„Î± / samples)
  - Î•Ï€Î¹ÎºÏÏÏ‰ÏƒÎ· / Validation: 2025 (11 Î´ÎµÎ¯Î³Î¼Î±Ï„Î± / samples)
- **ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· / Normalization**: StandardScaler (fitted on training data only)

### 3. Baseline Linear Regression (16 ÎœÎ¿Î½Ï„Î­Î»Î± / Models)

**Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ Ï€Î¿Ï… Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Î·ÎºÎ±Î½ / Configurations Tested:**

- 4 smoothing levels (raw, sigma1, sigma2, sigma3)
- 4 lag windows (3, 6, 9, 12 months)
- **Î£ÏÎ½Î¿Î»Î¿ / Total**: 16 configurations

**ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î¡ÏÎ¸Î¼Î¹ÏƒÎ· / Best Configuration:**

- sigma3, 12 lags â†’ RMSE: $0.03, RÂ²: 1.0000

### 4. Polynomial Regression (32 ÎœÎ¿Î½Ï„Î­Î»Î± / Models)

**Î ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ· / Approach:**

- Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Î·ÎºÎ±Î½ ÎŸÎ›Î‘ Ï„Î± 16 baseline configurations / Tested ALL 16 baseline configurations
- Î Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¬ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î²Î±Î¸Î¼Î¿Ï 2 / Degree-2 polynomial features
- Ridge (L2) ÎºÎ±Î¹ Lasso (L1) regularization
- Grid search Î³Î¹Î± alpha: [0.001, 0.01, 0.1, 1.0, 10.0]

**ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ ÎœÎ¿Î½Ï„Î­Î»Î¿ / Best Model:**

- sigma3, 9 lags, Ridge, Î±=0.001 â†’ RMSE: $4.19, RÂ²: 0.9978

### 5. Dimensionality Reduction (48 ÎœÎ¿Î½Ï„Î­Î»Î± / Models)

**ÎœÎ­Î¸Î¿Î´Î¿Î¹ / Methods:**

1. **PCA**: 95% explained variance threshold
2. **CFS**: Correlation-based Feature Selection
3. **Sequential Forward Selection**: Wrapper method (50% features target)

**Î‘Î½Î¬Î»Ï…ÏƒÎ· Î³Î¹Î± ÎŸÎ›Î‘ Ï„Î± 16 configurations / Applied to ALL 16 configurations**

**ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ ÎœÎ¿Î½Ï„Î­Î»Î¿ / Best Model:**

- sigma3, 12 lags, Forward Selection (12 features) â†’ RMSE: $0.03, RÂ²: 1.0000

### 6. Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎœÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÏÎ½ Î¤Î¹Î¼ÏÎ½ / Future Predictions

**ÎœÎµÎ¸Î¿Î´Î¿Î»Î¿Î³Î¯Î± / Methodology:**

- ÎšÎ±Ï„Î±ÏÏÎ±ÎºÏ„ÏÎ´Î·Ï‚ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· / Cascading prediction
- Î”ÎµÎºÎ­Î¼Î²ÏÎ¹Î¿Ï‚ 2025: Î§ÏÎ®ÏƒÎ· Î¹ÏƒÏ„Î¿ÏÎ¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Using historical data
- Î™Î±Î½Î¿Ï…Î¬ÏÎ¹Î¿Ï‚ 2026: Î§ÏÎ®ÏƒÎ· Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·Ï‚ Î”ÎµÎºÎµÎ¼Î²ÏÎ¯Î¿Ï… Ï‰Ï‚ input / Using December prediction as input

---

## Î’Î‘Î£Î™ÎšÎ‘ Î•Î¥Î¡Î—ÎœÎ‘Î¤Î‘ / KEY FINDINGS

### 1. Î•Ï€Î¯Î´ÏÎ±ÏƒÎ· Smoothing / Smoothing Impact

âœ… **sigma3 (Gaussian Ïƒ=3) Ï€Î±ÏÎ¬Î³ÎµÎ¹ Ï„Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± / produces best results**

- ÎœÎµÎ¹ÏÎ½ÎµÎ¹ Î¸ÏŒÏÏ…Î²Î¿ Ï‡Ï‰ÏÎ¯Ï‚ Î±Ï€ÏÎ»ÎµÎ¹Î± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏÎ½ Ï„Î¬ÏƒÎµÏ‰Î½ / Reduces noise without losing important trends
- Validation RMSE: $0.03 vs $78.81 (raw data)

### 2. Î Î±ÏÎ¬Î¸Ï…ÏÎ¿ Î¥ÏƒÏ„Î­ÏÎ·ÏƒÎ·Ï‚ / Lag Window

âœ… **12 Î¼Î®Î½ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î²Î­Î»Ï„Î¹ÏƒÏ„Î¿ / 12 months is optimal**

- Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ = ÎºÎ±Î»ÏÏ„ÎµÏÎ· Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· / More features = better prediction
- Î‘Ï€Î¿Ï†Ï…Î³Î® overfitting Î»ÏŒÎ³Ï‰ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ / Avoiding overfitting through regularization

### 3. Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½ / Model Comparison

| ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î± / Category | ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ RMSE / Best RMSE | Î Î»ÎµÎ¿Î½ÎµÎºÏ„Î®Î¼Î±Ï„Î± / Advantages                                               |
| -------------------- | ------------------------- | ------------------------------------------------------------------------ |
| **Baseline**         | $0.03                     | Î‘Ï€Î»ÏŒ, ÎµÏÎ¼Î·Î½ÎµÏÏƒÎ¹Î¼Î¿ / Simple, interpretable                                |
| **Polynomial**       | $4.19                     | Î£Ï…Î»Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Î¼Î·-Î³ÏÎ±Î¼Î¼Î¹ÎºÏŒÏ„Î·Ï„Î± / Captures non-linearity                     |
| **Dim-Reduction**    | $0.03                     | Î›Î¹Î³ÏŒÏ„ÎµÏÎ± Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬, Î¯Î´Î¹Î± Î±Ï€ÏŒÎ´Î¿ÏƒÎ· / Fewer features, same performance |

### 4. Feature Selection

âœ… **Sequential Forward Selection ÎµÏ€Î¹Ï„Ï…Î³Ï‡Î¬Î½ÎµÎ¹ Î¬ÏÎ¹ÏƒÏ„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± / achieves excellent results**

- ÎœÎµÎ¯Ï‰ÏƒÎ· Î±Ï€ÏŒ 24 â†’ 12 Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ / Reduction from 24 â†’ 12 features
- Î”Î¹Î±Ï„Î®ÏÎ·ÏƒÎ· RÂ²=1.0000 / Maintaining RÂ²=1.0000
- Î‘Ï€Î»Î¿ÏÏƒÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿, Ï„Î±Ï‡ÏÏ„ÎµÏÎ· Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· / Simpler model, faster prediction

---

## Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘ Î‘ÎÎ‘ Î•Î¡Î“Î‘Î£Î™Î‘ / RESULTS BY TASK

### âœ… Î•ÏÎ³Î±ÏƒÎ¯Î± Î‘ / Task A: Baseline Linear Regression

- **Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± ÎœÎ¿Î½Ï„Î­Î»Î± / Models Trained**: 16
- **ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î¡ÏÎ¸Î¼Î¹ÏƒÎ· / Best Config**: sigma3, 12 lags
- **Validation RMSE**: $0.03
- **Validation RÂ²**: 1.0000

### âœ… Î•ÏÎ³Î±ÏƒÎ¯Î± Î’ / Task B: Polynomial Regression Î¼Îµ ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· / with Regularization

- **Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± ÎœÎ¿Î½Ï„Î­Î»Î± / Models Trained**: 32 (16 Ridge + 16 Lasso)
- **ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ ÎœÎ¿Î½Ï„Î­Î»Î¿ / Best Model**: Ridge (sigma3, 9 lags, Î±=0.001)
- **Validation RMSE**: $4.19
- **Validation RÂ²**: 0.9978

### âœ… Î•ÏÎ³Î±ÏƒÎ¯Î± Î“ / Task C: ÎœÎµÎ¯Ï‰ÏƒÎ· Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÏ‰Î½ / Dimensionality Reduction

- **Î•ÎºÏ€Î±Î¹Î´ÎµÏ…Î¼Î­Î½Î± ÎœÎ¿Î½Ï„Î­Î»Î± / Models Trained**: 48 (16 PCA + 16 CFS + 16 SFS)
- **ÎšÎ±Î»ÏÏ„ÎµÏÎ· ÎœÎ­Î¸Î¿Î´Î¿Ï‚ / Best Method**: Sequential Forward Selection
- **ÎšÎ±Î»ÏÏ„ÎµÏÎ· Î¡ÏÎ¸Î¼Î¹ÏƒÎ· / Best Config**: sigma3, 12 lags (12 features)
- **Validation RMSE**: $0.03
- **Validation RÂ²**: 1.0000

### âœ… Î•ÏÎ³Î±ÏƒÎ¯Î± Î” / Task D: Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎœÎµÎ»Î»Î¿Î½Ï„Î¹ÎºÏÎ½ Î¤Î¹Î¼ÏÎ½ / Future Predictions

- **Î”ÎµÎºÎ­Î¼Î²ÏÎ¹Î¿Ï‚ 2025 / December 2025**: $1,175.48
- **Î™Î±Î½Î¿Ï…Î¬ÏÎ¹Î¿Ï‚ 2026 / January 2026**: $1,175.95
- **ÎœÎ­Î¸Î¿Î´Î¿Ï‚ / Method**: ÎšÎ±Ï„Î±ÏÏÎ±ÎºÏ„ÏÎ´Î·Ï‚ Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Î¼Îµ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿ baseline / Cascading prediction with best baseline

---

## Î‘Î¡Î§Î•Î™Î‘ Î‘ÎÎ‘Î¦ÎŸÎ¡Î©Î / REPORT FILES

1. **COMPREHENSIVE_96_MODELS_REPORT_EL_EN.txt**

   - Î”Î¯Î³Î»Ï‰ÏƒÏƒÎ· ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ® Î±Î½Î¬Î»Ï…ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ 96 Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
   - Bilingual comprehensive analysis of all 96 models

2. **baseline_linear_regression_results.csv**

   - Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± 16 baseline Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
   - Detailed results for 16 baseline models

3. **polynomial_regression_all_models_results.csv**

   - Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± 32 polynomial Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
   - Detailed results for 32 polynomial models

4. **dimensionality_reduction_all_models_results.csv**

   - Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± 48 dim-reduction Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
   - Detailed results for 48 dim-reduction models

5. **baseline_predictions_dec_jan_2025_2026.csv**
   - Î ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ Î³Î¹Î± Î”ÎµÎºÎ­Î¼Î²ÏÎ¹Î¿ 2025 & Î™Î±Î½Î¿Ï…Î¬ÏÎ¹Î¿ 2026
   - Predictions for December 2025 & January 2026

---

## Î‘Î Î•Î™ÎšÎŸÎÎ™Î£Î•Î™Î£ / VISUALIZATIONS

### Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼ÎµÎ½Î± Î“ÏÎ±Ï†Î®Î¼Î±Ï„Î± / Generated Plots

1. **Data Smoothing Comparison** (`smoothing_comparison.png`)

   - Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· raw ÎºÎ±Î¹ smoothed data
   - Comparison of raw and smoothed data

2. **Baseline Performance** (`baseline_performance_by_config.png`)

   - Î‘Ï€ÏŒÎ´Î¿ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ 16 baseline configurations
   - Performance of all 16 baseline configurations

3. **Comprehensive Predictions** (`comprehensive_predictions_comparison.png`)

   - Î£ÏÎ³ÎºÏÎ¹ÏƒÎ· Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÏ‰Î½ ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Î¼Î¿Î½Ï„Î­Î»Ï‰Î½
   - Comparison of predictions across all models

4. **Best Model Forecast** (`best_model_forecast_with_history.png`)
   - Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± + Ï€ÏÎ¿Î²Î»Î­ÏˆÎµÎ¹Ï‚ ÎºÎ±Î»ÏÏ„ÎµÏÎ¿Ï… Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
   - Historical data + best model predictions

---

## Î¤Î•Î§ÎÎ™ÎšÎ•Î£ Î›Î•Î Î¤ÎŸÎœÎ•Î¡Î•Î™Î•Î£ / TECHNICAL DETAILS

### Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎµÏ‚ / Libraries Used

- **NumPy**: Î‘ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¿Î¯ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼Î¿Î¯ / Numerical computations
- **Pandas**: Î§ÎµÎ¹ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ / Data manipulation
- **Scikit-learn**: ÎœÎ¿Î½Ï„Î­Î»Î± ML & Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚ / ML models & metrics
- **SciPy**: Gaussian filtering
- **Matplotlib**: Î‘Ï€ÎµÎ¹ÎºÎ¿Î½Î¯ÏƒÎµÎ¹Ï‚ / Visualizations
- **Requests**: API calls

### Î‘Î»Î³ÏŒÏÎ¹Î¸Î¼Î¿Î¹ / Algorithms

1. **LinearRegression**: Baseline models
2. **Ridge**: L2 regularization (Ï€Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¬ / polynomial)
3. **Lasso**: L1 regularization (Ï€Î¿Î»Ï…Ï‰Î½Ï…Î¼Î¹ÎºÎ¬ / polynomial)
4. **PCA**: Unsupervised dimensionality reduction
5. **CFS**: Filter-based feature selection
6. **SequentialFeatureSelector**: Wrapper-based selection

---

## Î”Î—Î›Î©Î£Î— Î”Î™Î“Î›Î©Î£Î£Î™Î‘Î£ Î¥Î ÎŸÎ£Î¤Î—Î¡Î™ÎÎ—Î£ / BILINGUAL SUPPORT DECLARATION

### Î•Î»Î»Î·Î½Î¹ÎºÎ® Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· / Greek Language Support

Î‘Ï…Ï„ÏŒ Ï„Î¿ Î­ÏÎ³Î¿ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï€Î»Î®ÏÎ· Î´Î¯Î³Î»Ï‰ÏƒÏƒÎ· Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· (Î•Î»Î»Î·Î½Î¹ÎºÎ¬-Î‘Î³Î³Î»Î¹ÎºÎ¬) ÏƒÎµ ÏŒÎ»Î± Ï„Î± Î±ÏÏ‡ÎµÎ¯Î±:

This project includes full bilingual support (Greek-English) across all files:

âœ… **Python Scripts**: ÎŒÎ»Î± Ï„Î± modules Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ docstrings ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬ ÎºÎ±Î¹ Î‘Î³Î³Î»Î¹ÎºÎ¬  
âœ… **Python Scripts**: All modules contain docstrings in both Greek and English

âœ… **Reports**: ÎŒÎ»ÎµÏ‚ Î¿Î¹ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ½Ï„Î±Î¹ ÏƒÎµ Î´Î¯Î³Î»Ï‰ÏƒÏƒÎ· Î¼Î¿ÏÏ†Î®  
âœ… **Reports**: All reports generated in bilingual format

âœ… **Documentation**: README ÎºÎ±Î¹ Ï„ÎµÏ‡Î½Î¹ÎºÎ¬ Î­Î³Î³ÏÎ±Ï†Î± ÏƒÎµ Î±Î¼Ï†ÏŒÏ„ÎµÏÎµÏ‚ Ï„Î¹Ï‚ Î³Î»ÏÏƒÏƒÎµÏ‚  
âœ… **Documentation**: README and technical documents in both languages

âœ… **Terminology**: Î“Î»Ï‰ÏƒÏƒÎ¬ÏÎ¹Î¿ ML ÏŒÏÏ‰Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿ ÏƒÏ„Î¿ `ML_TERMINOLOGY_GLOSSARY_EL_EN.md`  
âœ… **Terminology**: ML terminology glossary available in `ML_TERMINOLOGY_GLOSSARY_EL_EN.md`

---

## Î‘ÎÎ‘Î Î‘Î¡Î‘Î“Î©Î“Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î / REPRODUCIBILITY

Î“Î¹Î± Î±Î½Î±Ï€Î±ÏÎ±Î³Ï‰Î³Î® Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ / To reproduce results:

1. Î’ÎµÎ²Î±Î¹Ï‰Î¸ÎµÎ¯Ï„Îµ ÏŒÏ„Î¹ Î­Ï‡ÎµÏ„Îµ Python 3.8+ / Ensure you have Python 3.8+
2. Î•Î³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÏ„Îµ dependencies / Install dependencies
3. Î¡Ï…Î¸Î¼Î¯ÏƒÏ„Îµ Alpha Vantage API key ÏƒÏ„Î¿ `.env` / Configure Alpha Vantage API key in `.env`
4. Î•ÎºÏ„ÎµÎ»Î­ÏƒÏ„Îµ ÏŒÎ»Î± Ï„Î± scripts Î¼Îµ Ï„Î· ÏƒÎµÎ¹ÏÎ¬ / Run all scripts in sequence
5. Î•Î»Î­Î³Î¾Ï„Îµ `results/` Î³Î¹Î± Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ / Check `results/` for reports

**Î£Î·Î¼ÎµÎ¯Ï‰ÏƒÎ· / Note**: Î¤Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹Î±Ï†Î­ÏÎ¿Ï…Î½ ÎµÎ»Î±Ï†ÏÏÏ‚ Î»ÏŒÎ³Ï‰ ÎµÎ½Î·Î¼ÎµÏÏÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.  
Results may vary slightly due to data updates.

---

## Î£Î¥Î“Î“Î¡Î‘Î¦Î•Î‘Î£ & Î Î›Î—Î¡ÎŸÎ¦ÎŸÎ¡Î™Î•Î£ / AUTHOR & INFORMATION

**ÎœÎ¬Î¸Î·Î¼Î± / Course**: Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ­Ï‚ ÎœÎ­Î¸Î¿Î´Î¿Î¹ ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ®Ï‚ ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚ / Statistical Methods of Machine Learning  
**Î•ÏÎ³Î±ÏƒÎ¯Î± / Assignment**: Task 1 - Stock Price Prediction  
**Î£ÏÎ¼Î²Î¿Î»Î¿ ÎœÎµÏ„Î¿Ï‡Î®Ï‚ / Stock Symbol**: NFLX (Netflix, Inc.)  
**Î§ÏÎ¿Î½Î¹ÎºÎ® Î ÎµÏÎ¯Î¿Î´Î¿Ï‚ / Time Period**: ÎœÎ¬Î¹Î¿Ï‚ 2002 - ÎÎ¿Î­Î¼Î²ÏÎ¹Î¿Ï‚ 2025 / May 2002 - November 2025  
**Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎœÎ¿Î½Ï„Î­Î»Î± / Total Models**: 96

---

## Î‘ÎÎ‘Î¦ÎŸÎ¡Î•Î£ & Î Î—Î“Î•Î£ / REFERENCES & SOURCES

1. **Alpha Vantage API**: https://www.alphavantage.co/
2. **Scikit-learn Documentation**: https://scikit-learn.org/
3. **Gaussian Filtering**: SciPy ndimage module
4. **ML Terminology Glossary**: `ML_TERMINOLOGY_GLOSSARY_EL_EN.md`

---

## Î‘Î”Î•Î™Î‘ / LICENSE

Î‘Ï…Ï„ÏŒ Ï„Î¿ Î­ÏÎ³Î¿ Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎµ Î³Î¹Î± ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿ÏÏ‚ ÏƒÎºÎ¿Ï€Î¿ÏÏ‚.  
This project was created for educational purposes.

---

**Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î± Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯Î±Ï‚ Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚ / Last Updated**: ÎÎ¿Î­Î¼Î²ÏÎ¹Î¿Ï‚ 2025 / November 2025
